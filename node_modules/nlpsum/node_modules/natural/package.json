{
  "name": "natural",
  "description": "General natural language (tokenizing, stemming (English, Russian, Spanish), classification, inflection, phonetics, tfidf, WordNet, jaro-winkler, Levenshtein distance, Dice's Coefficient) facilities for node.",
  "version": "0.1.26",
  "homepage": "https://github.com/NaturalNode/natural",
  "repository": {
    "type": "git",
    "url": "git://github.com/NaturalNode/natural.git"
  },
  "engines": {
    "node": ">=0.4.10"
  },
  "dependencies": {
    "sylvester": ">= 0.0.12",
    "apparatus": ">= 0.0.6",
    "underscore": ">=1.3.1"
  },
  "devDependencies": {
    "uubench": "0.0.x"
  },
  "author": {
    "name": "Chris Umbel",
    "email": "chris@chrisumbel.com"
  },
  "keywords": [
    "natural",
    "language",
    "porter",
    "lancaster",
    "stemmer",
    "bayes",
    "classifier",
    "phonetic",
    "metaphone",
    "inflector",
    "wordnet",
    "tf-idf",
    "logistic",
    "regression",
    "doublemetaphone",
    "double",
    "jaro-winkler",
    "levenshtein",
    "distance"
  ],
  "main": "./lib/natural/index.js",
  "maintainers": [
    {
      "name": "Chris Umbel",
      "email": "chris@chrisumbel.com",
      "url": "http://www.chrisumbel.com"
    },
    {
      "name": "Rob Ellis",
      "email": "rob@silentrob.me"
    }
  ],
  "readme": "natural\n=======\n\n\"Natural\" is a general natural language facility for node.js. Tokenizing,\nstemming, classification, phonetics, tf-idf, WordNet, string similarity,\nand some inflections are currently supported.\n\nIt's still in the early stages, so we're very interested in bug reports,\ncontributions and the like.\n\nNote that many algorithms from Rob Ellis's [node-nltools](https://github.com/NaturalNode/node-nltools) are\nbeing merged into this project and will be maintained from here onward.\n\nAt the moment, most of the algorithms are English-specific, but in the long-term, some diversity\nwill be in order. Thanks to Polyakov Vladimir, Russian stemming has been added!, Thanks to David Przybilla, Spanish stemming has been added!.\n\nAside from this README, the only documentation is [this DZone article](http://www.dzone.com/links/r/using_natural_a_nlp_module_for_nodejs.html) and [here on my blog](http://www.chrisumbel.com/article/node_js_natural_language_porter_stemmer_lancaster_bayes_naive_metaphone_soundex), which is a bit older.\n\nLooking for Help Maintaining Natural!\n-------------------------------------\n\nI'm having trouble devoting the time necessary to maintain natural. While I'm certainly not\nleaving the project I'd like someone to take over the day-to-day maintenance of dealing with\nissues, pull requests and driving the direction of the software moving forward. Please contact\nchris@chrisumbel.com if you're interested!\n\n\nInstallation\n------------\n\nIf you're just looking to use natural without your own node application,\nyou can install via NPM like so:\n\n    npm install natural\n\nIf you're interested in contributing to natural, or just hacking on it, then by all\nmeans fork away!\n\nTokenizers\n----------\n\nWord, Regexp, and [Treebank tokenizers](http://www.cis.upenn.edu/~treebank/tokenization.html) are provided for breaking text up into\narrays of tokens:\n\n```javascript\nvar natural = require('natural'),\n  tokenizer = new natural.WordTokenizer();\nconsole.log(tokenizer.tokenize(\"your dog has flees.\"));\n// [ 'your', 'dog', 'has', 'flees' ]\n```\n\nThe other tokenizers follow a similar pattern:\n\n```javascript\ntokenizer = new natural.TreebankWordTokenizer();\nconsole.log(tokenizer.tokenize(\"my dog hasn't any flees.\"));\n// [ 'my', 'dog', 'has', 'n\\'t', 'any', 'flees', '.' ]\n\ntokenizer = new natural.RegexpTokenizer({pattern: /\\-/});\nconsole.log(tokenizer.tokenize(\"flee-dog\"));\n// [ 'flee', 'dog' ]\n\ntokenizer = new natural.WordPunctTokenizer();\nconsole.log(tokenizer.tokenize(\"my dog hasn't any flees.\"));\n// [ 'my',  'dog',  'hasn',  '\\'',  't',  'any',  'flees',  '.' ]\n```\n\nString Distance\n----------------------\nNatural provides an implementation of the [Jaro–Winkler](http://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) string distance measuring algorithm.\nThis will return a number between 0 and 1 which tells how closely the strings match (0 = not at all, 1 = exact match):\n\n```javascript\nvar natural = require('natural');\nconsole.log(natural.JaroWinklerDistance(\"dixon\",\"dicksonx\"))\nconsole.log(natural.JaroWinklerDistance('not', 'same'));\n```\n\nOutput:\n\n```javascript\n0.7466666666666666\n0\n```\n\nNatural also offers support for Levenshtein distances:\n\n```javascript\nvar natural = require('natural');\nconsole.log(natural.LevenshteinDistance(\"ones\",\"onez\"));\nconsole.log(natural.LevenshteinDistance('one', 'one'));\n```\n\nOutput:\n\n```javascript\n1\n0\n```\n\nThe cost of the three edit operations are modifiable for Levenshtein:\n\n```javascript\nconsole.log(natural.LevenshteinDistance(\"ones\",\"onez\", {\n    insertion_cost: 1,\n    deletion_cost: 1,\n    substitution_cost: 1\n}));\n```\n\nOutput:\n\n```javascript\n1\n```\n\nAnd Dice's co-efficient:\n\n```javascript\nvar natural = require('natural');\nconsole.log(natural.DiceCoefficient('thing', 'thing'));\nconsole.log(natural.DiceCoefficient('not', 'same'));\n```\n\nOutput:\n\n```javascript\n1\n0\n```\n\nStemmers\n--------\n\nCurrently stemming is supported via the [Porter](http://tartarus.org/martin/PorterStemmer/index.html) and [Lancaster](http://www.comp.lancs.ac.uk/computing/research/stemming/) (Paice/Husk) algorithms.\n\n```javascript\nvar natural = require('natural');\n```\n\nThis example uses a Porter stemmer. \"word\" is returned.\n\n```javascript\nconsole.log(natural.PorterStemmer.stem(\"words\")); // stem a single word\n```\n\n in Russian:\n\n```javascript\nconsole.log(natural.PorterStemmerRu.stem(\"падший\"));\n```\n\n in Spanish:\n\n```javascript\nconsole.log(natural.PorterStemmerEs.stem(\"jugaría\"));\n```\n\n`attach()` patches `stem()` and `tokenizeAndStem()` to String as a shortcut to\n`PorterStemmer.stem(token)`. `tokenizeAndStem()` breaks text up into single words\nand returns an array of stemmed tokens.\n\n```javascript\nnatural.PorterStemmer.attach();\nconsole.log(\"i am waking up to the sounds of chainsaws\".tokenizeAndStem());\nconsole.log(\"chainsaws\".stem());\n```\n\nthe same thing can be done with a Lancaster stemmer:\n\n```javascript\nnatural.LancasterStemmer.attach();\nconsole.log(\"i am waking up to the sounds of chainsaws\".tokenizeAndStem());\nconsole.log(\"chainsaws\".stem());\n```\n\nClassifiers\n----------------------\n\nTwo classifiers are currently supported, [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) and [logistic regression](http://en.wikipedia.org/wiki/Logistic_regression).\nThe following examples use the BayesClassifier class, but the \nLogisticRegressionClassifier class could be substituted instead.\n\n```javascript\nvar natural = require('natural'),\n  classifier = new natural.BayesClassifier();\n```\n\nYou can train the classifier on sample text. It will use reasonable defaults to\ntokenize and stem the text.\n\n```javascript\nclassifier.addDocument('i am long qqqq', 'buy');\nclassifier.addDocument('buy the q''s', 'buy');\nclassifier.addDocument('short gold', 'sell');\nclassifier.addDocument('sell gold', 'sell');\n\nclassifier.train();\n```\n\nOutputs \"sell\"\n\n```javascript\nconsole.log(classifier.classify('i am short silver'));\n```\n\nOutputs \"buy\"\n\n```javascript\nconsole.log(classifier.classify('i am long copper'));\n```\n\nYou have access to the set of matched classes and the associated value from the classifier.\n\nOutputs:\n\n```javascript\n[ { label: 'sell', value: 0.39999999999999997 },\n  { label: 'buy', value: 0.19999999999999998 } ]\n```\n\nFrom this:\n\n```javascript\nconsole.log(classifier.getClassifications('i am long copper'));\n```\n\nThe classifier can also be trained with and can classify arrays of tokens, strings, or\nany mixture of the two. Arrays let you use entirely custom data with your own\ntokenization/stemming, if you choose to implement it.\n\n```javascript\nclassifier.addDocument(['sell', 'gold'], 'sell');\n```\n\nThe training process can be monitored by subscribing to the event `trainedWithDocument` that's emitted by the classifier, this event's emitted each time a document is finished being trained against:\n\n    classifier.events.on('trainedWithDocument', function (obj) {\n       console.log(obj);\n       /* {\n       *   total: 23 // There are 23 total documents being trained against\n       *   index: 12 // The index/number of the document that's just been trained against\n       *   doc: {...} // The document that has just been indexed\n       */ }\n    });\n\nA classifier can also be persisted and recalled so you can reuse a training\n\n```javascript\nclassifier.save('classifier.json', function(err, classifier) {\n    // the classifier is saved to the classifier.json file!\n});\n```\n\nTo recall from the classifier.json saved above:\n\n```javascript\nnatural.BayesClassifier.load('classifier.json', null, function(err, classifier) {\n    console.log(classifier.classify('long SUNW'));\n    console.log(classifier.classify('short SUNW'));\n});\n```\n\nA classifier can also be serialized and deserialized like so:\n\n```javascript\nvar classifier = new natural.BayesClassifier();\nclassifier.addDocument(['sell', 'gold'], 'sell');\nclassifier.addDocument(['buy', 'silver'], 'buy');\n\n// serialize\nvar raw = JSON.stringify(classifier);\n// deserialize\nvar restoredClassifier = natural.BayesClassifier.restore(JSON.parse(raw));\nconsole.log(restoredClassifier.classify('i should sell that'));\n```\n\nPhonetics\n---------\n\nPhonetic matching (sounds-like) matching can be done with the [SoundEx](http://en.wikipedia.org/wiki/Soundex),\n[Metaphone](http://en.wikipedia.org/wiki/Metaphone) or [DoubleMetaphone](http://en.wikipedia.org/wiki/Metaphone#Double_Metaphone) algorithms\n\n```javascript\nvar natural = require('natural'),\n    metaphone = natural.Metaphone, soundEx = natural.SoundEx;\n\nvar wordA = 'phonetics';\nvar wordB = 'fonetix';\n```\n\nTo test the two words to see if they sound alike:\n\n```javascript\nif(metaphone.compare(wordA, wordB))\n    console.log('they sound alike!');\n```\n\nThe raw phonetics are obtained with `process()`:\n\n```javascript\nconsole.log(metaphone.process('phonetics'));\n```\n\nA maximum code length can be supplied:\n\n```javascript\nconsole.log(metaphone.process('phonetics', 3));\n```\n\n`DoubleMetaphone` deals with two encodings returned in an array. This\nfeature is experimental and subject to change:\n\n```javascript\nvar natural = require('natural'),\n  dm = natural.DoubleMetaphone;\n\nvar encodings = dm.process('Matrix');\nconsole.log(encodings[0]);\nconsole.log(encodings[1]);\n```\n\nAttaching will patch String with useful methods:\n\n```javascript\nmetaphone.attach();\n```\n\n`soundsLike` is essentially a shortcut to `Metaphone.compare`:\n\n```javascript\nif(wordA.soundsLike(wordB))\n    console.log('they sound alike!');\n```\n\nThe raw phonetics are obtained with `phonetics()`:\n\n```javascript\nconsole.log('phonetics'.phonetics());\n```\n\nFull text strings can be tokenized into arrays of phonetics (much like how tokenization-to-arrays works for stemmers):\n\n```javascript\nconsole.log('phonetics rock'.tokenizeAndPhoneticize());\n```\n\nSame module operations applied with `SoundEx`:\n\n```javascript\nif(soundEx.compare(wordA, wordB))\n    console.log('they sound alike!');\n```\n\nThe same String patches apply with `soundEx`:\n\n```javascript\nsoundEx.attach();\n\nif(wordA.soundsLike(wordB))\n    console.log('they sound alike!');\n\nconsole.log('phonetics'.phonetics());\n```\n\nInflectors\n----------\n\n### Nouns\n\nNouns can be pluralized/singularized with a `NounInflector`:\n\n```javascript\nvar natural = require('natural'),\nnounInflector = new natural.NounInflector();\n```\n\nTo pluralize a word (outputs \"radii\"):\n\n```javascript\nconsole.log(nounInflector.pluralize('radius'));\n```\n\nTo singularize a word (outputs \"beer\"):\n\n```javascript\nconsole.log(nounInflector.singularize('beers'));\n```\n\nLike many of the other features, String can be patched to perform the operations\ndirectly. The \"Noun\" suffix on the methods is necessary, as verbs will be\nsupported in the future.\n\n```javascript\nnounInflector.attach();\nconsole.log('radius'.pluralizeNoun());\nconsole.log('beers'.singularizeNoun());\n```\n\n### Numbers\n\nNumbers can be counted with a CountInflector:\n\n```javascript\nvar countInflector = natural.CountInflector;\n```\n\nOutputs \"1st\":\n\n```javascript\nconsole.log(countInflector.nth(1));\n```\n\nOutputs \"111th\":\n\n```javascript\nconsole.log(countInflector.nth(111));\n```\n\n### Present Tense Verbs\n\nPresent Tense Verbs can be pluralized/singularized with a PresentVerbInflector.\nThis feature is still experimental as of 0.0.42, so use with caution, and please\nprovide feedback.\n\n```javascript\nvar verbInflector = new natural.PresentVerbInflector();\n```\n\nOutputs \"becomes\":\n\n```javascript\nconsole.log(verbInflector.singularize('become'));\n```\n\nOutputs \"become\":\n\n```javascript\nconsole.log(verbInflector.pluralize('becomes'));\n```\n\nLike many other natural modules, `attach()` can be used to patch strings with\nhandy methods.\n\n```javascript\nverbInflector.attach();\nconsole.log('walk'.singularizePresentVerb());\nconsole.log('walks'.pluralizePresentVerb());\n```\n\n\nN-Grams\n-------\n\nn-grams can be obtained for either arrays or strings (which will be tokenized\nfor you):\n\n```javascript\nvar NGrams = natural.NGrams;\n```\n\n### bigrams\n\n```javascript\nconsole.log(NGrams.bigrams('some words here'));\nconsole.log(NGrams.bigrams(['some',  'words',  'here']));\n```\n\nBoth of the above output: `[ [ 'some', 'words' ], [ 'words', 'here' ] ]`\n\n### trigrams\n\n```javascript\nconsole.log(NGrams.trigrams('some other words here'));\nconsole.log(NGrams.trigrams(['some',  'other', 'words',  'here']));\n```\n\nBoth of the above output: `[ [ 'some', 'other', 'words' ],\n  [ 'other', 'words', 'here' ] ]`\n\n### arbitrary n-grams\n\n```javascript\nconsole.log(NGrams.ngrams('some other words here for you', 4));\nconsole.log(NGrams.ngrams(['some', 'other', 'words', 'here', 'for',\n    'you'], 4));\n```\n\nThe above outputs: `[ [ 'some', 'other', 'words', 'here' ],\n  [ 'other', 'words', 'here', 'for' ],\n  [ 'words', 'here', 'for', 'you' ] ]`\n\ntf-idf\n-----\n\n[Term Frequency–Inverse Document Frequency (tf-idf)](http://en.wikipedia.org/wiki/Tf%E2%80%93idf) is implemented to determine how important a word (or words) is to a \ndocument relative to a corpus. The following example will add four documents to \na corpus and determine the weight of the word \"node\" and then the weight of the \nword \"ruby\" in each document.\n\n```javascript\nvar natural = require('natural'),\n    TfIdf = natural.TfIdf,\n    tfidf = new TfIdf();\n\ntfidf.addDocument('this document is about node.');\ntfidf.addDocument('this document is about ruby.');\ntfidf.addDocument('this document is about ruby and node.');\ntfidf.addDocument('this document is about node. it has node examples');\n\nconsole.log('node --------------------------------');\ntfidf.tfidfs('node', function(i, measure) {\n    console.log('document #' + i + ' is ' + measure);\n});\n\nconsole.log('ruby --------------------------------');\ntfidf.tfidfs('ruby', function(i, measure) {\n    console.log('document #' + i + ' is ' + measure);\n});\n```\n\nThe above outputs:\n\n```\nnode --------------------------------\ndocument #0 is 1.4469189829363254\ndocument #1 is 0\ndocument #2 is 1.4469189829363254\ndocument #3 is 2.8938379658726507\nruby --------------------------------\ndocument #0 is 0\ndocument #1 is 1.466337068793427\ndocument #2 is 1.466337068793427\ndocument #3 is 0\n```\n\nThis approach can also be applied to individual documents.\n\nThe following example measures the term \"node\" in the first and second documents.\n\n```javascript\nconsole.log(tfidf.tfidf('node', 0));\nconsole.log(tfidf.tfidf('node', 1));\n```\n\nA TfIdf instance can also load documents from files on disk.\n\n```javascript\nvar tfidf = new TfIdf();\ntfidf.addFileSync('data_files/one.txt');\ntfidf.addFileSync('data_files/two.txt');\n```\n\nMultiple terms can be measured as well, with their weights being added into\na single measure value. The following example determines that the last document\nis the most relevent to the words \"node\" and \"ruby\".\n\n```javascript\nvar natural = require('natural'),\n    TfIdf = natural.TfIdf,\n    tfidf = new TfIdf();\n\ntfidf.addDocument('this document is about node.');\ntfidf.addDocument('this document is about ruby.');\ntfidf.addDocument('this document is about ruby and node.');\n\ntfidf.tfidfs('node ruby', function(i, measure) {\n    console.log('document #' + i + ' is ' + measure);\n});\n```\n\nThe above outputs:\n\n```\ndocument #0 is 1.2039728043259361\ndocument #1 is 1.2039728043259361\ndocument #2 is 2.4079456086518722\n```\n\nThe examples above all use strings, which case natural to automatically tokenize the input.\nIf you wish to perform your own tokenization or other kinds of processing, you\ncan do so, then pass in the resultant arrays later. This approach allows you to bypass natural's \ndefault preprocessing.\n\n```javascript\nvar natural = require('natural'),\n    TfIdf = natural.TfIdf,\n    tfidf = new TfIdf();\n\ntfidf.addDocument(['document', 'about', 'node']);\ntfidf.addDocument(['document', 'about', 'ruby']);\ntfidf.addDocument(['document', 'about', 'ruby', 'node']);\ntfidf.addDocument(['document', 'about', 'node', 'node', 'examples']);\n\ntfidf.tfidfs(['node', 'ruby'], function(i, measure) {\n    console.log('document #' + i + ' is ' + measure);\n});\n```\n\nIt's possible to retrieve a list of all terms in a document, sorted by their\nimportance.\n\n```javascript\ntfidf.listTerms(0 /*document index*/).forEach(function(item) {\n    console.log(item.term + ': ' + item.tfidf);\n});\n```\n\nA TfIdf instance can also be serialized and deserialzed for save and recall.\n\n```javascript\nvar tfidf = new TfIdf();\ntfidf.addDocument('document one', 'un');\ntfidf.addDocument('document Two', 'deux');\nvar s = JSON.stringify(tfidf);\n// save \"s\" to disk, database or otherwise\n\n// assuming you pulled \"s\" back out of storage.\nvar tfidf = new TfIdf(JSON.parse(s));\n```\n\nTries\n-----\n\nTries are a very efficient data structure used for prefix-based searches. \nNatural comes packaged with a basic Trie implementation wich can support match collection along a path,\nexistance search and prefix search.\n\n### Building The Trie\n\nYou need to add words to build up the dictionary of the Trie, this is an example of basic Trie set up:\n\n```javascript\nvar natural = require('natural'),\n    Trie = natural.Trie;\n\nvar trie = new Trie();\n\n// Add one string at a time\ntrie.addString(\"test\");\n\n// Or add many strings\ntrie.addStrings([\"string1\", \"string2\", \"string3\"]);\n```\n\n### Searching\n\n#### Contains\n\nThe most basic operation on a Trie is to see if a search string is marked as a word in the Trie.\n\n```javascript\nconsole.log(trie.contains(\"test\")); // true\nconsole.log(trie.contains(\"asdf\")); // false\n```\n\n### Find Prefix\n\nThe find prefix search will find the longest prefix that is identified as a word in the trie.\nIt will also return the remaining portion of the string which it was not able to match.\n\n```javascript\nconsole.log(trie.findPrefix(\"tester\"));     // ['test', 'er']\nconsole.log(trie.findPrefix(\"string4\"));    // [null, '4']\nconsole.log(trie.findPrefix(\"string3\"));    // ['string3', '']\n```\n\n### All Prefixes on Path\n\nThis search will return all prefix matches along the search string path.\n\n```javascript\ntrie.addString(\"tes\");\ntrie.addString(\"est\");\nconsole.log(trie.findMatchesOnPath(\"tester\")); // ['tes', 'test'];\n```\n\n### Case-Sensitivity\n\nBy default the trie is case-sensitive, you can use it in case-_in_sensitive mode by passing `false` \nto the Trie constructor.\n\n```javascript\ntrie.contains(\"TEST\"); // false\n\nvar ciTrie = new Trie(false);\nciTrie.addString(\"test\");\nciTrie.contains(\"TEsT\"); // true\n```\nIn the case of the searches which return strings, all strings returned will be in lower case if you are in case-_in_sensitive mode.\n\nWordNet\n-------\n\nOne of the newest and most experimental features in natural is WordNet integration. Here's an\nexample of using natural to look up definitions of the word node. To use the WordNet module,\nfirst install the WordNet database files using the [WNdb module](https://github.com/moos/WNdb):\n\n    npm install WNdb\n\n(For node < v0.6, please use 'npm install WNdb@3.0.0')\n\nKeep in mind that the WordNet integration is to be considered experimental at this point,\nand not production-ready. The API is also subject to change.\n\nHere's an example of looking up definitions for the word, \"node\".\n\n```javascript\nvar wordnet = new natural.WordNet();\n\nwordnet.lookup('node', function(results) {\n    results.forEach(function(result) {\n        console.log('------------------------------------');\n        console.log(result.synsetOffset);\n        console.log(result.pos);\n        console.log(result.lemma);\n        console.log(result.synonyms);\n        console.log(result.pos);\n        console.log(result.gloss);\n    });\n});\n```\n\nGiven a synset offset and a part of speech, a definition can be looked up directly.\n\n```javascript\nvar wordnet = new natural.WordNet();\n\nwordnet.get(4424418, 'n', function(result) {\n    console.log('------------------------------------');\n    console.log(result.lemma);\n    console.log(result.pos);\n    console.log(result.gloss);\n    console.log(result.synonyms);\n});\n```\n\nIf you have _manually_ downloaded the WordNet database files, you can pass the folder to the constructor:\n\n```javascript\nvar wordnet = new natural.WordNet('/my/wordnet/dict');\n```\n\nAs of v0.1.11, WordNet data files are no longer automatically downloaded.\n\nPrinceton University \"About WordNet.\" WordNet. Princeton University. 2010. <http://wordnet.princeton.edu>\n\nDevelopment\n-----------\nWhen developing, please:\n\n+ Write unit tests\n+ Make sure your unit tests pass\n\nThe current configuration of the unit tests requires the following environment variable to be set:\n\n    export NODE_PATH=.\n\n\nLicense\n-------\n\nCopyright (c) 2011, 2012 Chris Umbel, Rob Ellis, Russell Mull\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\nWordNet License\n---------------\n\nThis license is available as the file LICENSE in any downloaded version of WordNet.\nWordNet 3.0 license: (Download)\n\nWordNet Release 3.0 This software and database is being provided to you, the LICENSEE, by Princeton University under the following license. By obtaining, using and/or copying this software and database, you agree that you have read, understood, and will comply with these terms and conditions.: Permission to use, copy, modify and distribute this software and database and its documentation for any purpose and without fee or royalty is hereby granted, provided that you agree to comply with the following copyright notice and statements, including the disclaimer, and that the same appear on ALL copies of the software, database and documentation, including modifications that you make for internal use or for distribution. WordNet 3.0 Copyright 2006 by Princeton University. All rights reserved. THIS SOFTWARE AND DATABASE IS PROVIDED \"AS IS\" AND PRINCETON UNIVERSITY MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, PRINCETON UNIVERSITY MAKES NO REPRESENTATIONS OR WARRANTIES OF MERCHANT- ABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE LICENSED SOFTWARE, DATABASE OR DOCUMENTATION WILL NOT INFRINGE ANY THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS. The name of Princeton University or Princeton may not be used in advertising or publicity pertaining to distribution of the software and/or database. Title to copyright in this software, database and any associated documentation shall at all times remain with Princeton University and LICENSEE agrees to preserve same.\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/NaturalNode/natural/issues"
  },
  "_id": "natural@0.1.26",
  "dist": {
    "shasum": "633b71f4d72f87ff5dd0c84cc2a81da5eff5d14d"
  },
  "_from": "natural@latest",
  "_resolved": "https://registry.npmjs.org/natural/-/natural-0.1.26.tgz"
}
